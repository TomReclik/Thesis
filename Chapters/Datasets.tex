\chapter{Datasets}

A consistently labeled dataset is crucial for the performance of a classifier. Due to the required time 


Inconsistencies will lead to the network adapting its weights


 Inconsistencies will lead to the network adapting 


Inconsistencies will lead to the network changing its weights and parameters 



Since the dataset is labeled by multiple persons, clear class definitions are necessary in order to arrive at the same conclusion for similar damage sites. 



A consistently labeled dataset is crucial for the performance of a classifier, requiring clear class definitions. If a network is trained on a dataset

A consistently labeled dataset is crucial for the performance of a classifier. 


 If the class definitions are not clear enough, different researchers will classify damage sites depending on their personal opinion and not inconsistencies will arise. Since the CNN adjust its weights depending on the images shown together with correct label, if the given label is faulty, the networks weights and features that are being extracted will be corrected in the wrong way. This behavior will render the classifier useless. \\

In order to gather a consistently labeled dataset, internal preliminary studies were performed in order to assess whether, based on the class definitions given in chapter \ref{cha:DualPhaseSteels}, lead to different researchers arriving at the same class, for the same damage site. \\




\section{Reliability of Training Data}

Due to the need of consistently labeled datasets, for the training process of the classifier, a study was performed internally beforehand. Five experts were asked to classify $25$ damage sites given the following descriptions. 
\begin{itemize}[label={}]
\item \textbf{Inclusion}: Inclusions, either holes left from preparation or actual inclusions.
\item \textbf{Martensite Cracking}: Brittle cracked martensite islands.
\item \textbf{Interface Decohesion}: Damage to the martensite/ferrite boundary.
\item \textbf{Boundary Decohesion}: Damage to ferrite grain boundaries.
\item \textbf{Evolved Damage}: More than one active damage mechanism, e.g. martensite cracking evolved into ductile damage in ferrite.
\end{itemize}
The agreement with the damage classes determined beforehand can be seen in table \ref{tab:Reliability}. Major problems arose with boundary decohesions and evolved damage sites. Due to the high concentration of martensite in the dual-phase steel used in this work boundary decohesions occur very rarely. Problems with evolved damage sites come from the lack of a clear threshold after which a damage site falls into the class of evolved damage sites. Due to this, boundary decohesions and evolved damages were not used for the classification algorithm to distinguish between. Furthermore the class notch effect was introduced. This class is defined by a damage site between tips of two martensite islands. It is possible that the two martensite islands were connected before the nucleation of a void or that there was a ferrite bridge between the two islands. The defining characteristic for this class is a stress concentration, enabled through the hard martensite, at this point in the microstructure.

\begin{table}[H]
 \begin{center}
  \begin{tabular}{@{} *2l @{}} \toprule[2pt]
   Damage Category & Accuracy \\\midrule
   Martensite Cracking & $85 \%$   \\ 
   Inclusion  & $84 \%$ \\ 
   Interface Decohesion  & $76 \% $ \\
   Evolved & $56\%$ \\
   Boundary Decohesion & $44 \%$ \\ \bottomrule[2pt]

  \end{tabular}
 \end{center}
 \caption{Agreement for the classification of damage sites by hand. }
 \label{tab:Reliability}
\end{table}

\section{Influence of an Incorrectly Labeled Dataset}

The influence of an incorrectly labeled dataset was studied using the Canadian Institute for Advanced Research 10 (CIFAR-10) \cite{Krizhevsky2009} dataset, with a CNN, whose architecture is shown in \ref{acc:EERACN}. The network was trained for $30$ epochs with an Adam optimizer \cite{Sharma2017} with a learning rate of $0.0005$ and other parameters set to default. The network was once trained with a correctly labeled dataset and then with a dataset with $30\%$ of the datapoints mislabeled, corresponding to the average mislabeling rate from \ref{tab:Reliability}. The baseline accuracy for a correctly labeled dataset with constant seeds among experiments and fluctuations resulting from the use of GPU is $0.73\pm 0.01$. Training the network with mislabeled data and evaluating the trained network on a dataset labeled correctly the accuracy drops to $0.66\pm 0.01$. Because the data used for the training of a network distinguishing between damage mechanisms is completely labeled by hand the test dataset would also be labeled incorrectly. The accuracy of a network evaluated on a test dataset with inconstistent labeling leads to a further drop in the accuracy to $0.43\pm 0.01$, due to correct predictions being labeled as wrong.\\


\section{Datasets}
The datasets were obtained in two ways. At first labelImg \cite{labelImg} was used. With this tool it is possible to mark damage sites in SEM panoramas, requiring the user to search for them by zooming into the micrograph. Later once the localization algorithm was implemented as explained in chapter \ref{cha:Localization}, significantly reducing the required time for the creation of a dataset by negating the need to localize damage sites by hand. The two methods are shown in figure \ref{fig:labelimg}. \\

During deformation artifacts can form on the surface of the micrograph. A few examples of such artifacts are shown in figure \ref{fig:artifacts}. Due to the preparation of the sample these do not show in ex-situ experiments and very rarely in early stages of in-situ experiments. The dataset is therefore split into two categories. The first one consists of surface micrographs not containing artifacts on the probes set, while the second one consists of surface micrographs containing said artifacts. \\

The available data for each damage mechanism and category after labeling is shown in table \ref{tab:Dataset}.

%The data is split into two categories. The first category are surface micrographs that were taken right after preparing the sample. Due to the preparation these do not contain artifacts from the deformation of the sample. This first category consists of ex-situ experiments and the first stage of in-situ experiments. Later stages of in-situ experiments fall into the second category, 
%The data is split into three parts. Firstly data from ex-situ experiments, with different grades of stress. The dual-phase steel was prepared before each recording with the SEM, therefore no artifacts can be seen on the surface of the sheet. Secondly data from the first stage of in-situ experiments, this data is  The second round of experiments was performed in-situ. Due to the in-situ nature of those experiments at higher rates of deformation, recordings contain artifacts on the surface of the probe. The datasets with the number of damage sites in each category can be seen in table \ref{tab:Dataset}. \\ 

\begin{table}[H]
\begin{center}
\begin{tabular}{@{} *5l @{}} \toprule[2pt]
Training set &  \multicolumn{4}{c}{Damage Mechanism}   \\\midrule
 & Inc & MC & ID & NE   \\ 
ex-situ  & 379 & 691 & 788 & 449\\ 
in-situ  & 192 & 823 & 586 & 392 \\ \bottomrule
all  & 571 & 1514 & 1374 & 841\\\bottomrule[2pt]

\end{tabular}
 \caption{The number of damage sites found in the ex-situ and in-situ experiments per class (inclusion (Inc), martensite cracking (MC), interface decohesion (ID), and notch effect (NE)).}
 \label{tab:Dataset}
\end{center}
\end{table}